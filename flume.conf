# define an event agent
# we use a fan out strategy with 2 sinks: logger and hdfs

agent.sources = r1
agent.sinks = s1 s2
agent.channels = c1 c2

agent.sources.r1.channels = c1 c2
agent.sinks.s1.channel = c1
agent.sinks.s2.channel = c2

agent.sources.r1.type = netcat
agent.sources.r1.bind = 0.0.0.0
agent.sources.r1.port = 44444
agent.sources.r1.interceptors = i1
agent.sources.r1.interceptors.i1.type = REGEX_EXTRACTOR
agent.sources.r1.interceptors.i1.regex = (\\d+-\\d+-\\d+ \\d+:\\d+:\\d+),
agent.sources.r1.interceptors.i1.serializers = s1
agent.sources.r1.interceptors.i1.serializers.s1.type = org.apache.flume.interceptor.RegexExtractorInterceptorMillisSerializer
agent.sources.r1.interceptors.i1.serializers.s1.name = timestamp
agent.sources.r1.interceptors.i1.serializers.s1.pattern = yyyy-MM-dd HH:mm:ss

# hdfs sink to put events into
agent.sinks.s1.type = hdfs
agent.sinks.s1.hdfs.path = /flume/events/%Y/%m/%d
agent.sinks.s1.hdfs.writeFormat = Text
agent.sinks.s1.hdfs.batchSize = 1000
agent.sinks.s1.hdfs.rollSize = 0
agent.sinks.s1.hdfs.rollCount = 500

# logging sink for debugging
agent.sinks.s2.type = logger

# memory channels
agent.channels.c1.type = memory
# HDFS is damn slow, so give it larger buffer
agent.channels.c1.capacity = 50000
agent.channels.c1.transactionCapacity = 1000

agent.channels.c2.type = memory
agent.channels.c2.capacity = 10000
agent.channels.c2.transactionCapacity = 1000